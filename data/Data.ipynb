{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import getpass\n",
    "import pickle\n",
    "import io\n",
    "import time\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Grab data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Login\n",
    "https://www.statistikdaten.bayern.de/genesis/online?Menu=Anmeldung#abreadcrumb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "username = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "password = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GenesisApi:\n",
    "\n",
    "    def __init__(self, username, password, polling_rate=5):\n",
    "        self.username = username\n",
    "        self.password = password\n",
    "        self.polling_rate = polling_rate\n",
    "\n",
    "        self.__base_url = 'https://www.statistikdaten.bayern.de/genesisWS/rest/2020/'\n",
    "\n",
    "        self.__base_params = {\n",
    "            'username': username,\n",
    "            'password': password,\n",
    "            'language': 'de'\n",
    "        }\n",
    "\n",
    "        self.__default_table_params = self.__base_params.copy()\n",
    "        self.__default_table_params.update({\n",
    "            'name': '',\n",
    "            'area': 'all',\n",
    "            'compress': 'false',\n",
    "            'transpose': 'false',\n",
    "            'startyear': '',\n",
    "            'endyear': '',\n",
    "            'timeslices': '',\n",
    "            'regionalvariable': '',\n",
    "            'regionalkey': '',\n",
    "            'classifyingkey1': '',\n",
    "            'classifyingvariable2': '',\n",
    "            'classifyingkey2': '',\n",
    "            'classifyingvariable3': '',\n",
    "            'classifyingkey3': '',\n",
    "            'job': 'true'\n",
    "        })\n",
    "\n",
    "        self.__default_jobs_params = self.__base_params.copy()\n",
    "        self.__default_jobs_params.update({\n",
    "            'selection': '',\n",
    "            'searchcriterion': 'code',\n",
    "            'sortcriterion': 'code',\n",
    "            'type': 'all',\n",
    "            'area': 'all',\n",
    "            'pagelength': '100'\n",
    "        })\n",
    "\n",
    "        self.__default_result_params = self.__base_params.copy()\n",
    "        self.__default_result_params.update({\n",
    "            'name': '',\n",
    "            'area': 'all',\n",
    "            'compress': 'false'\n",
    "        })\n",
    "\n",
    "    def check_login(self):\n",
    "        response = requests.get(self.__base_url + 'helloworld/logincheck', params=self.__base_params)\n",
    "        b'{\"Status\":\"Sie wurden erfolgreich an- und abgemeldet!\",\"Username\":\"GB3U65P838\"}'\n",
    "        try:\n",
    "            return response.json()['Status'] == 'Sie wurden erfolgreich an- und abgemeldet!'\n",
    "        except Exception as e:\n",
    "            return False\n",
    "\n",
    "    def get_table(self, name, startyear=''):\n",
    "        startyear = str(startyear)\n",
    "\n",
    "        params = self.__default_table_params.copy()\n",
    "        params['name'] = name\n",
    "        params['startyear'] = startyear\n",
    "\n",
    "        response = requests.get(self.__base_url + 'data/table', params=params)\n",
    "\n",
    "        data = response.json()\n",
    "        code = data['Status']['Code']\n",
    "        if (code == 0):  # Success\n",
    "            return data\n",
    "        elif (code == 99):  # Table is too big a job has been created\n",
    "            print('Table is too big, created a job.')\n",
    "            result_name = data['Status']['Content'].split(':', 1)[1][1:]\n",
    "            return self.get_job_result(result_name)\n",
    "        else:\n",
    "            params['password'] = '***'\n",
    "            print('Error requesting ' + name + ' with params:', params, 'response:', data)\n",
    "            return data\n",
    "\n",
    "    def is_job_ready(self, name):\n",
    "        params = self.__default_jobs_params.copy()\n",
    "        params['selection'] = 'Werteabruf ' + name\n",
    "\n",
    "        response = requests.get(self.__base_url + 'catalogue/jobs', params=params)\n",
    "        try:\n",
    "            return response.json()['List'][0]['State'] == 'Fertig'\n",
    "        except Exception as e:\n",
    "            return False\n",
    "\n",
    "    def delete_job_result(self, name):\n",
    "        params = self.__default_result_params.copy()\n",
    "        params['name'] = name\n",
    "        response = requests.get(self.__base_url + 'profile/removeResult', params=params)\n",
    "        return response\n",
    "\n",
    "    def get_job_result(self, name):\n",
    "        params = self.__default_result_params.copy()\n",
    "        params['name'] = name\n",
    "\n",
    "        while (not self.is_job_ready(name)):\n",
    "            print('Data is not ready waiting ' + str(self.polling_rate) + ' seconds longer.')\n",
    "            time.sleep(self.polling_rate)\n",
    "\n",
    "        response = requests.get(self.__base_url + 'data/result', params=params)\n",
    "        self.delete_job_result(name)\n",
    "        return response.json()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test login"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "genesis = GenesisApi(username, password)\n",
    "genesis.check_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data\n",
    "\n",
    "Note: This takes a long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "responses_area = {}\n",
    "\n",
    "# 33111-201r 1980, 1984, 1988, 1992, 1996, 2000, 2004, 2008, 2009, 2010, 2011, 2012, 2013\n",
    "# 33111-001r 2014 - 2020\n",
    "\n",
    "for year in [1980, 1984, 1988, 1992, 1996, 2000, 2004, 2008, 2009, 2010, 2011, 2012, 2013]:\n",
    "    print('Requesting table for the year ' + str(year))\n",
    "    response = genesis.get_table('33111-201r', year)\n",
    "    print('Got data')\n",
    "    responses_area[str(year)] = response\n",
    "\n",
    "for year in range(2014, 2020 + 1):\n",
    "    print('Requesting table for the year ' + str(year))\n",
    "    response = genesis.get_table('33111-001r', year)\n",
    "    print('Got data')\n",
    "    responses_area[str(year)] = response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_to_dataframe(response, start_at_line, date_line, header_line):\n",
    "    raw_content = response['Object']['Content']\n",
    "    content = raw_content.split('\\n', start_at_line)\n",
    "    date = content[date_line].split(';', 1)[0]\n",
    "    csv = io.StringIO(content[header_line] + '\\n' + content[start_at_line].split('\\n__________', 1)[0])\n",
    "    df = pd.read_csv(csv, ';')\n",
    "    df['date'] = pd.to_datetime(date, format='%d.%m.%Y')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs = list()\n",
    "for year, response in responses_area.items():\n",
    "    df = convert_to_dataframe(response, start_at_line=10, date_line=5, header_line=8)\n",
    "\n",
    "    column_names = df.columns.values\n",
    "    column_names[0] = 'AGS'\n",
    "    column_names[1] = 'Gemeinde'\n",
    "    df.columns = column_names\n",
    "\n",
    "    for column_name in column_names[2: len(column_names) - 1]:\n",
    "        df[column_name] = pd.to_numeric(df[column_name].str.replace(',', '.'), errors='coerce')\n",
    "\n",
    "    df['Gemeinde'] = df['Gemeinde'].str.strip()\n",
    "\n",
    "    dfs.append(df)\n",
    "\n",
    "df_area = pd.concat(dfs, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_area.to_pickle('df_area.pickle')\n",
    "\n",
    "with open('responses_area.pickle', 'wb') as f:\n",
    "    pickle.dump(responses_area, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_area = pd.read_pickle('df_area.pickle')\n",
    "\n",
    "with open('responses_area.pickle', 'rb') as f:\n",
    "    responses_area = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "used = [\n",
    "    \"Wohnen\",\n",
    "    \"Grünanlage\",\n",
    "    \"Friedhof\",\n",
    "    \"sonstige Erholungsfläche\",\n",
    "    \"11000 Wohnbaufläche\",\n",
    "    \"18100 Sportanlage\",\n",
    "    \"18200 Freizeitanlage\",\n",
    "    \"19000 Friedhof\",\n",
    "    \"18300 Erholungsfläche\",\n",
    "    \"18400 Grünanlage\",\n",
    "\n",
    "    \"Gewerbe, Industrie\",\n",
    "    \"Betriebsfläche (ohne Abbauland)\",\n",
    "    \"Flächen anderer Nutzung (ohne Unland, Friedhof)\",\n",
    "    \"12100 Industrie und Gewerbe\",\n",
    "    \"12200 Handel und Dienstleistung\",\n",
    "    \"12300 Versorgungsanlage\",\n",
    "    \"12400 Entsorgung\",\n",
    "    \"13000 Halde\",\n",
    "    \"17000 Fläche besonderer funktionaler Prägung\",\n",
    "\n",
    "    \"16000 Fläche gemischter Nutzung\",\n",
    "    \"sonstige Gebäude- und Freifläche\",\n",
    "\n",
    "    \"Straße, Weg, Platz\",\n",
    "    \"sonstige Verkehrsfläche\",\n",
    "    \"21000 Straßenverkehr\",\n",
    "    \"22000 Weg\",\n",
    "    \"23000 Platz\",\n",
    "    \"24000 Bahnverkehr\",\n",
    "    \"25000 Flugverkehr\",\n",
    "    \"26000 Schiffsverkehr\",\n",
    "]\n",
    "unused = [\n",
    "    \"Abbauland\",\n",
    "    \"14000 Bergbaubetrieb\",\n",
    "    \"15000 Tagebau, Grube, Steinbruch\",\n",
    "    \"Moor\",\n",
    "    \"Landwirtschaftsfläche (ohne Moor, Heide)\",\n",
    "    \"Heide\",\n",
    "    \"Waldfläche\",\n",
    "    \"Unland\",\n",
    "    \"31100 Ackerland\",\n",
    "    \"31200 Grünland\",\n",
    "    \"31300 Gartenland\",\n",
    "    \"31400 Weingarten\",\n",
    "    \"31500 Obstplantage\",\n",
    "    \"32000 Wald\",\n",
    "    \"33000 Gehölz\",\n",
    "    \"34000 Heide\",\n",
    "    \"35000 Moor\",\n",
    "    \"36000 Sumpf\",\n",
    "    \"37000 Unland, Vegetationslose Fläche\",\n",
    "\n",
    "    \"Wasserfläche\",\n",
    "    \"42000 Hafenbecken\",\n",
    "    \"41000 Fließgewässer\",\n",
    "    \"43000 Stehendes Gewässer\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {\n",
    "    \"living\": [  # Wohnen\n",
    "        \"Wohnen\",\n",
    "        \"11000 Wohnbaufläche\",\n",
    "    ],\n",
    "\n",
    "    \"industry\": [  # Industrie / Gewerbe\n",
    "        \"Gewerbe, Industrie\",\n",
    "        \"Betriebsfläche (ohne Abbauland)\",\n",
    "        \"Flächen anderer Nutzung (ohne Unland, Friedhof)\",\n",
    "        \"12100 Industrie und Gewerbe\",\n",
    "        \"12200 Handel und Dienstleistung\",\n",
    "        \"12300 Versorgungsanlage\",\n",
    "        \"12400 Entsorgung\",\n",
    "        \"13000 Halde\",\n",
    "        \"17000 Fläche besonderer funktionaler Prägung\",\n",
    "    ],\n",
    "\n",
    "    \"misc_industry_living\": [  # Sonstiges\n",
    "        \"Grünanlage\",\n",
    "        \"Friedhof\",\n",
    "        \"sonstige Erholungsfläche\",\n",
    "        \"sonstige Gebäude- und Freifläche\",\n",
    "        \"16000 Fläche gemischter Nutzung\",\n",
    "        \"18100 Sportanlage\",\n",
    "        \"18200 Freizeitanlage\",\n",
    "        \"18300 Erholungsfläche\",\n",
    "        \"18400 Grünanlage\",\n",
    "        \"19000 Friedhof\",\n",
    "    ],\n",
    "\n",
    "    \"transport_infrastructure\": [  # Verkehrsflächen\n",
    "        \"Straße, Weg, Platz\",\n",
    "        \"sonstige Verkehrsfläche\",\n",
    "        \"21000 Straßenverkehr\",\n",
    "        \"22000 Weg\",\n",
    "        \"23000 Platz\",\n",
    "        \"24000 Bahnverkehr\",\n",
    "        \"25000 Flugverkehr\",\n",
    "        \"26000 Schiffsverkehr\",\n",
    "    ],\n",
    "\n",
    "    \"nature\": [  # Natur\n",
    "        \"Moor\",\n",
    "        \"Landwirtschaftsfläche (ohne Moor, Heide)\",\n",
    "        \"Heide\",\n",
    "        \"Waldfläche\",\n",
    "        \"Unland\",\n",
    "        \"31100 Ackerland\",\n",
    "        \"31200 Grünland\",\n",
    "        \"31300 Gartenland\",\n",
    "        \"31400 Weingarten\",\n",
    "        \"31500 Obstplantage\",\n",
    "        \"32000 Wald\",\n",
    "        \"33000 Gehölz\",\n",
    "        \"34000 Heide\",\n",
    "        \"35000 Moor\",\n",
    "        \"36000 Sumpf\",\n",
    "        \"37000 Unland, Vegetationslose Fläche\",\n",
    "    ],\n",
    "\n",
    "    \"water\": [  # Wasser\n",
    "        \"Wasserfläche\",\n",
    "        \"42000 Hafenbecken\",\n",
    "        \"41000 Fließgewässer\",\n",
    "        \"43000 Stehendes Gewässer\",\n",
    "    ],\n",
    "\n",
    "    \"mining\": [  # Bergbau\n",
    "        \"Abbauland\",\n",
    "        \"14000 Bergbaubetrieb\",\n",
    "        \"15000 Tagebau, Grube, Steinbruch\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we classified all columns and used each only once\n",
    "all_columns = set(df_area.columns)\n",
    "\n",
    "for l in categories.values():\n",
    "    all_columns = all_columns - set(l)\n",
    "\n",
    "all_columns = all_columns - {'AGS', 'Gemeinde', 'Insgesamt', 'date'}\n",
    "\n",
    "if len(all_columns) != 0:\n",
    "    print(\"The categories\", all_columns, \"have not yet been categorized.\")\n",
    "\n",
    "if len(set(df_area.columns) - set(used) - set(unused) - {'AGS', 'Gemeinde', 'Insgesamt', 'date'}) != 0:\n",
    "    print(\"The categories\", all_columns, \"have not yet been categorized.\")\n",
    "\n",
    "for ((name1, l1), (name2, l2)) in itertools.combinations(categories.items(), 2):\n",
    "    if not set(l1).isdisjoint(l2):\n",
    "        print(name1, \"and\", name2, \"contain the same category.\")\n",
    "\n",
    "if not set(used).isdisjoint(unused):\n",
    "    print(\"used and unused contain the same category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "categories['used_area'] = used\n",
    "#categories['unused_area'] = unused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (name, category) in categories.items():\n",
    "    df_area[name] = df_area.loc[:, category].sum(axis=1)\n",
    "    df_area[name + '_percent'] = df_area[name] / df_area['Insgesamt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "to_delete = set()\n",
    "\n",
    "for (name, category) in categories.items():\n",
    "    to_delete.update(category)\n",
    "\n",
    "df_area.drop(to_delete, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_area.rename(columns={\"Insgesamt\": \"total\", \"Gemeinde\": \"municipality\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter unused municipalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_area = df_area[df_area[\"AGS\"] <= 9999]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "shortened_names = {\n",
    "    \"Aichach-Friedberg (Lkr)\": \"Aichach-Friedberg\",  #6\n",
    "    \"Altötting (Lkr)\": \"Altötting\",\n",
    "    \"Amberg (Krfr.St)\": \"Amberg\",\n",
    "    \"Amberg-Sulzbach (Lkr)\": \"Amberg-S. Lkr.\",  #4\n",
    "    \"Ansbach (Krfr.St)\": \"Ansbach\",\n",
    "    \"Ansbach (Lkr)\": \"Ansbach Lkr.\",\n",
    "    \"Aschaffenburg (Krfr.St)\": \"Aschaffenburg\",  #1\n",
    "    \"Aschaffenburg (Lkr)\": \"Aschaffenb. Lkr.\",  #2\n",
    "    \"Augsburg (Krfr.St)\": \"Augsburg\",\n",
    "    \"Augsburg (Lkr)\": \"Augsburg Lkr.\",\n",
    "    \"Bad Kissingen (Lkr)\": \"Bad Kissingen\",  #2\n",
    "    \"Bad Tölz-Wolfratshausen (Lkr)\": \"Bad Tölz-W.\",  #12\n",
    "    \"Bamberg (Krfr.St)\": \"Bamberg\",\n",
    "    \"Bamberg (Lkr)\": \"Bamberg Lkr.\",\n",
    "    \"Bayern\": \"Bayern\",\n",
    "    \"Bayreuth (Krfr.St)\": \"Bayreuth\",\n",
    "    \"Bayreuth (Lkr)\": \"Bayreuth Lkr.\",\n",
    "    \"Berchtesgadener Land (Lkr)\": \"Berchtesg. Land\",  #9\n",
    "    \"Cham (Lkr)\": \"Cham\",\n",
    "    \"Coburg (Krfr.St)\": \"Coburg\",\n",
    "    \"Coburg (Lkr)\": \"Coburg Lkr.\",\n",
    "    \"Dachau (Lkr)\": \"Dachau\",\n",
    "    \"Deggendorf (Lkr)\": \"Deggendorf\",\n",
    "    \"Dillingen a.d.Donau (Lkr)\": \"Dillingen a.d.D.\",  #8\n",
    "    \"Dingolfing-Landau (Lkr)\": \"Dingolfing-L.\",  #6\n",
    "    \"Donau-Ries (Lkr)\": \"Donau-Ries\",\n",
    "    \"Ebersberg (Lkr)\": \"Ebersberg\",\n",
    "    \"Eichstätt (Lkr)\": \"Eichstätt\",\n",
    "    \"Erding (Lkr)\": \"Erding\",\n",
    "    \"Erlangen (Krfr.St)\": \"Erlangen\",\n",
    "    \"Erlangen-Höchstadt (Lkr)\": \"Erlangen-H. Lkr.\",  #7\n",
    "    \"Forchheim (Lkr)\": \"Forchheim\",\n",
    "    \"Freising (Lkr)\": \"Freising\",\n",
    "    \"Freyung-Grafenau (Lkr)\": \"Freyung-G.\",  #5\n",
    "    \"Fürstenfeldbruck (Lkr)\": \"Fürstenfeldb.\",  #5\n",
    "    \"Fürth (Krfr.St)\": \"Fürth\",\n",
    "    \"Fürth (Lkr)\": \"Fürth Lkr.\",\n",
    "    \"Garmisch-Partenkirchen (Lkr)\": \"Garmisch-P.\",  #11\n",
    "    \"Günzburg (Lkr)\": \"Günzburg\",\n",
    "    \"Haßberge (Lkr)\": \"Haßberge\",\n",
    "    \"Hof (Krfr.St)\": \"Hof\",\n",
    "    \"Hof (Lkr)\": \"Hof Lkr.\",\n",
    "    \"Ingolstadt (Krfr.St)\": \"Ingolstadt\",\n",
    "    \"Kaufbeuren (Krfr.St)\": \"Kaufbeuren\",\n",
    "    \"Kelheim (Lkr)\": \"Kelheim\",\n",
    "    \"Kempten (Allgäu) (Krfr.St)\": \"Kempten (A.)\",  #4\n",
    "    \"Kitzingen (Lkr)\": \"Kitzingen\",\n",
    "    \"Kronach (Lkr)\": \"Kronach\",\n",
    "    \"Kulmbach (Lkr)\": \"Kulmbach\",\n",
    "    \"Landsberg am Lech (Lkr)\": \"Landsberg a.L.\",  #6\n",
    "    \"Landshut (Krfr.St)\": \"Landshut\",\n",
    "    \"Landshut (Lkr)\": \"Landshut Lkr.\",\n",
    "    \"Lichtenfels (Lkr)\": \"Lichtenfels\",\n",
    "    \"Lindau (Bodensee) (Lkr)\": \"Lindau (B.)\",  #6\n",
    "    \"Main-Spessart (Lkr)\": \"Main-Spessart\",  #2\n",
    "    \"Memmingen (Krfr.St)\": \"Memmingen\",\n",
    "    \"Miesbach (Lkr)\": \"Miesbach\",\n",
    "    \"Miltenberg (Lkr)\": \"Miltenberg\",\n",
    "    \"Mittelfranken\": \"Mittelfranken\",\n",
    "    \"Mühldorf a.Inn (Lkr)\": \"Mühldorf a.Inn\",  #3\n",
    "    \"München (Lkr)\": \"München Lkr.\",\n",
    "    \"München, Landeshauptstadt\": \"München\",  #9\n",
    "    \"Neu-Ulm (Lkr)\": \"Neu-Ulm\",\n",
    "    \"Neuburg-Schrobenhausen (Lkr)\": \"Neuburg-S.\",  #11\n",
    "    \"Neumarkt i.d.OPf. (Lkr)\": \"Neumarkt i.d.O.\",  #6\n",
    "    \"Neustadt a.d.Aisch-Bad Windsheim (Lkr)\": \"Neustadt a.d.A.-B.W.\",  #21\n",
    "    \"Neustadt a.d.Waldnaab (Lkr)\": \"Neustadt a.d.W.\",  #10\n",
    "    \"Niederbayern\": \"Niederbayern\",\n",
    "    \"Nürnberg (Krfr.St)\": \"Nürnberg\",\n",
    "    \"Nürnberger Land (Lkr)\": \"Nürnberger L. Lkr.\",  #4\n",
    "    \"Oberallgäu (Lkr)\": \"Oberallgäu\",\n",
    "    \"Oberbayern\": \"Oberbayern\",\n",
    "    \"Oberfranken\": \"Oberfranken\",\n",
    "    \"Oberpfalz\": \"Oberpfalz\",\n",
    "    \"Ostallgäu (Lkr)\": \"Ostallgäu\",\n",
    "    \"Passau (Krfr.St)\": \"Passau\",\n",
    "    \"Passau (Lkr)\": \"Passau Lkr.\",\n",
    "    \"Pfaffenhofen a.d.Ilm (Lkr)\": \"Pfaffenh. a.d.I.\",  #9\n",
    "    \"Regen (Lkr)\": \"Regen\",\n",
    "    \"Regensburg (Krfr.St)\": \"Regensburg\",\n",
    "    \"Regensburg (Lkr)\": \"Regensb. Lkr.\",\n",
    "    \"Rhön-Grabfeld (Lkr)\": \"Rhön-Grabfeld\",  #2\n",
    "    \"Rosenheim (Krfr.St)\": \"Rosenheim\",\n",
    "    \"Rosenheim (Lkr)\": \"Rosenheim Lkr.\",\n",
    "    \"Roth (Lkr)\": \"Roth\",\n",
    "    \"Rottal-Inn (Lkr)\": \"Rottal-Inn\",\n",
    "    \"Schwabach (Krfr.St)\": \"Schwabach\",\n",
    "    \"Schwaben\": \"Schwaben\",\n",
    "    \"Schwandorf (Lkr)\": \"Schwandorf\",\n",
    "    \"Schweinfurt (Krfr.St)\": \"Schweinfurt\",\n",
    "    \"Schweinfurt (Lkr)\": \"Schweinf. Lkr.\",\n",
    "    \"Starnberg (Lkr)\": \"Starnberg\",\n",
    "    \"Straubing (Krfr.St)\": \"Straubing\",\n",
    "    \"Straubing-Bogen (Lkr)\": \"Straubing-B. Lkr.\",  #4\n",
    "    \"Tirschenreuth (Lkr)\": \"Tirschenreuth\",  #2\n",
    "    \"Traunstein (Lkr)\": \"Traunstein\",\n",
    "    \"Unterallgäu (Lkr)\": \"Unterallgäu\",\n",
    "    \"Unterfranken\": \"Unterfranken\",\n",
    "    \"Weiden i.d.OPf. (Krfr.St)\": \"Weiden i.d.O.\",  #3\n",
    "    \"Weilheim-Schongau (Lkr)\": \"Weilheim-Sch.\",  #6\n",
    "    \"Weißenburg-Gunzenhausen (Lkr)\": \"Weißenburg-G.\",  #12\n",
    "    \"Wunsiedel i.Fichtelgebirge (Lkr)\": \"Wunsiedel i.F.\",  #15\n",
    "    \"Würzburg (Krfr.St)\": \"Würzburg\",\n",
    "    \"Würzburg (Lkr)\": \"Würzburg Lkr.\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_export = df_area.copy()\n",
    "df_export['date'] = df_export['date'].dt.strftime('%d.%m.%Y')\n",
    "df_export['municipality_short'] = df_export['municipality'].apply(lambda m: shortened_names[m])\n",
    "\n",
    "with open(\"../src/data/data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    df_export.to_json(f, orient=\"records\", force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def group_by_and_export(data, filename):\n",
    "    json = \"{\"\n",
    "    first = True\n",
    "    for date, inner_json in data.groupby(\"date\").apply(lambda x: x.to_json(orient='records')).items():\n",
    "        if not first:\n",
    "            json = json + \",\"\n",
    "        else:\n",
    "            first = False\n",
    "        json = json + '\"' + date + '\":' + inner_json\n",
    "    json = json + \"}\"\n",
    "\n",
    "    with open(\"../src/data/\" + filename + \".json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(json)\n",
    "        f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "group_by_and_export(df_export[df_export[\"AGS\"] <= 99], \"RBYear\")\n",
    "group_by_and_export(df_export[df_export[\"AGS\"] > 99], \"LKYear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Generate code for https://sankeymatic.com/build/\n",
    "# Then manually create 2 svg graphs\n",
    "# One with white text color and onw with black text color\n",
    "# Label position should be \"Right side\"\n",
    "# Width is 900px and height is 900 px\n",
    "# Margins are all 12, except right is 290\n",
    "# Space between Nodes is 10 px with a width of 8\n",
    "# Flows should use the source node's color\n",
    "\n",
    "df_sankey = df_area[(df_area[\"AGS\"] == 9) & (df_area[\"date\"] == pd.to_datetime(\"31.12.2020\", format='%d.%m.%Y'))]\n",
    "\n",
    "sankey = \"Gesamtfläche [29] Verbrauchte Fläche\\n\"\n",
    "sankey += \"Gesamtfläche [23] Unverbrauchte Fläche\\n\"\n",
    "\n",
    "category_names = {\n",
    "    \"living\": \"Wohnfläche\",\n",
    "    \"industry\": \"Industrie/Gewerbe\",\n",
    "    \"misc_industry_living\": \"Sonstiges\",\n",
    "    \"transport_infrastructure\": \"Verkehrsflächen\",\n",
    "    \"nature\": \"Natur\",\n",
    "    \"water\": \"Wasser\",\n",
    "    \"mining\": \"Bergbau\"\n",
    "}\n",
    "\n",
    "category_colors = {\n",
    "    \"living\": \"#FF375F\",\n",
    "    \"industry\": \"#FF9F0A\",\n",
    "    \"misc_industry_living\": \"#FFD60A\",\n",
    "    \"transport_infrastructure\": \"#8E8E93\",\n",
    "    \"nature\": \"#30D158\",\n",
    "    \"water\": \"#0A84FF\",\n",
    "    \"mining\": \"#BF5AF2\"\n",
    "}\n",
    "\n",
    "for category_name, name in category_names.items():\n",
    "    size = str(len(categories[category_name]))\n",
    "    if category_name == \"water\" or category_name == \"nature\" or category_name == \"mining\":\n",
    "        sankey += \"Unverbrauchte Fläche [\" + size + \"] \" + name + \"\\n\"\n",
    "    else:\n",
    "        sankey += \"Verbrauchte Fläche [\" + size + \"] \" + name + \"\\n\"\n",
    "    sankey += \":\" + name + \" \" + category_colors[category_name] + \"\\n\"\n",
    "\n",
    "for category_name, name in category_names.items():\n",
    "    sub_categories = categories[category_name]\n",
    "    color = category_colors[category_name]\n",
    "    for category in sub_categories:\n",
    "        sankey += name + \" [1] \" + category + \"\\n\"\n",
    "        sankey += \":\" + category + \" \" + color + \"\\n\"\n",
    "\n",
    "sankey += \":Verbrauchte Fläche #F00\\n\"\n",
    "sankey += \":Unverbrauchte Fläche #0F0\\n\"\n",
    "sankey += \":Gesamtfläche #004477\\n\"\n",
    "\n",
    "with open(\"sankey\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(sankey)\n",
    "    f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lookupMap = \"export const longNameMap = new Map();\\n\"\n",
    "#lookupMap += \"export const shortNameMap = new Map();\\n\"\n",
    "\n",
    "for name, short_name in shortened_names.items():\n",
    "    lookupMap += 'longNameMap.set(\"' + short_name + '\", \"' + name + '\");\\n'\n",
    "    #lookupMap += 'shortNameMap.set(\"' + name + '\", \"' + short_name + '\");\\n'\n",
    "\n",
    "with open(\"../src/utils/LookUp.ts\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(lookupMap)\n",
    "    f.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}